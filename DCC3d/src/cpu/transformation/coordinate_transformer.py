"""
åæ ‡è½¬æ¢ä¸æ—‹è½¬ä¸å˜æ€§æ¨¡å— - PyTorch å¯å¾®åˆ†ç‰ˆæœ¬
================================================================
è¿™æ˜¯æ•´ä¸ªç½‘ç»œçš„æ•°æ®é¢„å¤„ç†æ ¸å¿ƒï¼ˆæ”¯æŒåå‘ä¼ æ’­ï¼‰

æ ¸å¿ƒç‰¹æ€§ï¼š
- å®Œå…¨å¯å¾®åˆ†ï¼Œæ”¯æŒç«¯åˆ°ç«¯è®­ç»ƒ
- æ”¯æŒ GPU åŠ é€Ÿ
- å¯ä»¥ä½œä¸º nn.Module åµŒå…¥åˆ°ç¥ç»ç½‘ç»œä¸­
- æ‰¹é‡å¤„ç†ä¼˜åŒ–

åŠŸèƒ½ï¼šå°†"æ‚ä¹±çš„ç»å¯¹åæ ‡"å˜æˆ"æ•´é½ã€ç»Ÿä¸€ã€å¸¦æœ‰ç‰©ç†æ„ä¹‰çš„ç›¸å¯¹çƒåæ ‡"

æ ¸å¿ƒæµç¨‹ï¼š
1. å±€éƒ¨æ ¼ç‚¹åæ ‡æå–ä¸ä¸­å¿ƒè®¡ç®—
2. ç›¸å¯¹åæ ‡è®¡ç®— (å¹³ç§»ä¸å˜æ€§)
3. PCA æ—‹è½¬å¯¹é½ (æ—‹è½¬ä¸å˜æ€§) - å¯å¾®åˆ†ï¼
4. ç¬›å¡å°”åæ ‡è½¬çƒæåæ ‡ - å¯å¾®åˆ†ï¼
"""

from typing import Optional, Tuple
import sys

import torch
import torch.nn as nn

# å¤„ç†ç›¸å¯¹å¯¼å…¥
try:
    from .rotation_invariance import RotationInvarianceTorch
except ImportError:
    from rotation_invariance import RotationInvarianceTorch

# æ£€æµ‹ torch.compile å¯ç”¨æ€§ï¼ˆPyTorch 2.0+ï¼‰
TORCH_COMPILE_AVAILABLE = hasattr(torch, 'compile') and sys.version_info >= (3, 8)


class CoordinateTransformerTorch(nn.Module):
    """
    åæ ‡è½¬æ¢ä¸»ç±» (PyTorch å¯å¾®åˆ†ç‰ˆæœ¬)

    å°†ç»å¯¹åæ ‡è½¬æ¢ä¸ºæ—‹è½¬ä¸å˜çš„çƒæåæ ‡ç‰¹å¾
    æ‰€æœ‰æ“ä½œæ”¯æŒæ¢¯åº¦åå‘ä¼ æ’­

    Attributes:
        rotation_invariance: æ—‹è½¬ä¸å˜æ€§å¤„ç†å™¨
        center_method: ä¸­å¿ƒç‚¹è®¡ç®—æ–¹æ³• ('mean', 'median')
    """

    def __init__(
        self,
        center_method: str = "mean",
        use_pca: bool = True,
        pca_stabilize: bool = True,
        use_compile: bool = True,
    ):
        """
        åˆå§‹åŒ–åæ ‡è½¬æ¢å™¨

        Args:
            center_method: ä¸­å¿ƒç‚¹è®¡ç®—æ–¹æ³•
                - 'mean': å‡å€¼ä¸­å¿ƒï¼ˆé»˜è®¤ï¼Œå¯å¾®åˆ†ï¼‰
                - 'median': ä¸­å€¼ä¸­å¿ƒï¼ˆä¸å¯å¾®åˆ†ï¼ï¼‰
            use_pca: æ˜¯å¦ä½¿ç”¨PCAè¿›è¡Œæ—‹è½¬ä¸å˜æ€§å¤„ç†ï¼ˆé»˜è®¤Trueï¼‰
                - True: ä½¿ç”¨PCAå¯¹é½ï¼Œå®ç°æ—‹è½¬ä¸å˜æ€§ï¼ˆå¯å¾®åˆ†ï¼‰
                - False: è·³è¿‡PCAï¼Œç›´æ¥ä½¿ç”¨ç›¸å¯¹åæ ‡
            pca_stabilize: æ˜¯å¦åœ¨ PCA ä¸­ä½¿ç”¨æ•°å€¼ç¨³å®šåŒ–
            use_compile: æ˜¯å¦ä½¿ç”¨ torch.compile åŠ é€Ÿï¼ˆPyTorch 2.0+ï¼‰
                - True: ä½¿ç”¨ JIT ç¼–è¯‘åŠ é€Ÿï¼ˆé»˜è®¤ï¼‰
                - False: ä¸ä½¿ç”¨ç¼–è¯‘ï¼ˆå…¼å®¹æ¨¡å¼ï¼‰
        """
        super().__init__()
        self.center_method = center_method
        self.use_pca = use_pca
        self.use_compile = use_compile and TORCH_COMPILE_AVAILABLE

        if center_method == "median":
            print("è­¦å‘Š: median ä¸å¯å¾®åˆ†ï¼Œå°†åœ¨éœ€è¦æ¢¯åº¦æ—¶ä½¿ç”¨ mean")
        
        if self.use_compile and not TORCH_COMPILE_AVAILABLE:
            print(f"è­¦å‘Š: torch.compile ä¸å¯ç”¨ (PyTorch {torch.__version__})ï¼Œå›é€€åˆ°æ™®é€šæ¨¡å¼")
            self.use_compile = False

        self.rotation_invariance = RotationInvarianceTorch(stabilize=pca_stabilize)
        
        # ç¼–è¯‘æ ¸å¿ƒè®¡ç®—å‡½æ•°ä»¥åŠ é€Ÿ
        if self.use_compile:
            self._apply_pca_batch = torch.compile(self._apply_pca_batch_impl)
            print(f"âœ“ ä½¿ç”¨ torch.compile åŠ é€Ÿï¼ˆPyTorch {torch.__version__}ï¼‰")
        else:
            self._apply_pca_batch = self._apply_pca_batch_impl

    def extract_local_coordinates(
        self, global_coords: torch.Tensor, neighbor_indices: torch.Tensor
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        åŠŸèƒ½ 1: å±€éƒ¨æ ¼ç‚¹åæ ‡æå–ä¸ä¸­å¿ƒè®¡ç®—ï¼ˆå¯å¾®åˆ†ï¼‰

        ä»å…¨å±€åæ ‡ä¸­æå–å±€éƒ¨é‚»å±…åæ ‡ï¼Œå¹¶è®¡ç®—ä¸­å¿ƒç‚¹

        Args:
            global_coords: å…¨å±€åæ ‡ï¼Œå½¢çŠ¶ (N_total, 3)
            neighbor_indices: é‚»å±…ç´¢å¼•çŸ©é˜µï¼Œå½¢çŠ¶ (N_centers, K)

        Returns:
            local_coords: å±€éƒ¨åæ ‡ç°‡ï¼Œå½¢çŠ¶ (N_centers, K, 3)
            centers: ä¸­å¿ƒç‚¹åæ ‡ï¼Œå½¢çŠ¶ (N_centers, 3)

        å¯å¾®åˆ†æ€§ï¼š
            - ç´¢å¼•æ“ä½œï¼šPyTorch çš„é«˜çº§ç´¢å¼•æ”¯æŒæ¢¯åº¦ä¼ æ’­
            - å‡å€¼æ“ä½œï¼šå®Œå…¨å¯å¾®åˆ†
        """
        # æå–å±€éƒ¨åæ ‡ï¼ˆå¯å¾®åˆ†ç´¢å¼•ï¼‰
        local_coords = global_coords[neighbor_indices]  # (N_centers, K, 3)

        # è®¡ç®—ä¸­å¿ƒç‚¹åæ ‡ï¼ˆå¯å¾®åˆ†ï¼‰
        if self.center_method == "mean" or global_coords.requires_grad:
            centers = local_coords.mean(dim=1)  # (N_centers, 3)
        elif self.center_method == "median":
            # median ä¸å¯å¾®åˆ†ï¼Œä»…ç”¨äºæ¨ç†
            centers = local_coords.median(dim=1)[0]  # (N_centers, 3)
        else:
            raise ValueError(f"æœªçŸ¥çš„ä¸­å¿ƒè®¡ç®—æ–¹æ³•: {self.center_method}")

        return local_coords, centers

    def extract_local_features(
        self, global_features: torch.Tensor, neighbor_indices: torch.Tensor
    ) -> torch.Tensor:
        """
        å±æ€§è·é˜µé€šè¿‡é€‰ç‚¹è·é˜µæ‰©å±•ï¼ˆå¯å¾®åˆ†ï¼‰

        å°†å…¨å±€å±æ€§ç‰¹å¾é€šè¿‡é‚»å±…ç´¢å¼•æ‰©å±•ä¸ºå±€éƒ¨å±æ€§ç‰¹å¾
        è¿™å¯¹åº”æµç¨‹å›¾ä¸­çš„"å±æ€§è·é˜µé€šè¿‡é€‰ç‚¹è·é˜µæ‰©å±•"æ­¥éª¤

        Args:
            global_features: å…¨å±€å±æ€§ç‰¹å¾ï¼Œå½¢çŠ¶ (N_total, Ci)
                Ci æ˜¯å±æ€§ç‰¹å¾çš„ç»´åº¦ï¼ˆå¦‚åŸå­ç±»å‹ã€ç”µè·ç­‰ï¼‰
            neighbor_indices: é‚»å±…ç´¢å¼•çŸ©é˜µï¼Œå½¢çŠ¶ (N_centers, K)

        Returns:
            local_features: å±€éƒ¨å±æ€§ç‰¹å¾ï¼Œå½¢çŠ¶ (N_centers, K, Ci)

        å¯å¾®åˆ†æ€§ï¼š
            - ç´¢å¼•æ“ä½œï¼šå®Œå…¨å¯å¾®åˆ†ï¼Œæ¢¯åº¦å¯ä»¥ä¼ æ’­å› global_features

        ç¤ºä¾‹ï¼š
            å¦‚æœ global_features æ˜¯åŸå­ç±»å‹çš„ one-hot ç¼–ç  (N_total, 118)
            neighbor_indices æŒ‡å®šäº†æ¯ä¸ªä¸­å¿ƒç‚¹çš„ K ä¸ªé‚»å±…
            åˆ™è¿”å› (N_centers, K, 118)ï¼Œå³æ¯ä¸ªä¸­å¿ƒç‚¹çš„é‚»å±…çš„åŸå­ç±»å‹ç‰¹å¾
        """
        # é€šè¿‡ç´¢å¼•æå–å±€éƒ¨ç‰¹å¾ï¼ˆå¯å¾®åˆ†ï¼‰
        local_features = global_features[neighbor_indices]  # (N_centers, K, Ci)

        return local_features

    def expand_feature_matrix(
        self, data: torch.Tensor, features: torch.Tensor
    ) -> torch.Tensor:
        """
        ç‰¹å¾çŸ©é˜µæ‰©å±•ï¼ˆå¯å¾®åˆ†ï¼‰

        å°† (N, n) çš„æ•°æ®å’Œ (N, Ci) çš„ç‰¹å¾æ‰©å±•ä¸º (Ci, N, n) çš„è¾“å‡º
        è¿™å¯ä»¥ç”¨äºå°†èŠ‚ç‚¹ç‰¹å¾åº”ç”¨åˆ°é‚»å±…æ•°æ®ä¸Šï¼Œç”Ÿæˆå¤šé€šé“çš„ç‰¹å¾è¡¨ç¤º

        Args:
            data: æ•°æ®çŸ©é˜µï¼Œå½¢çŠ¶ (N, n)
                ä¾‹å¦‚ï¼šN ä¸ªèŠ‚ç‚¹ï¼Œæ¯ä¸ªèŠ‚ç‚¹æœ‰ n ä¸ªé‚»å±…æˆ– n ç»´æ•°æ®
            features: ç‰¹å¾çŸ©é˜µï¼Œå½¢çŠ¶ (N, Ci)
                ä¾‹å¦‚ï¼šN ä¸ªèŠ‚ç‚¹ï¼Œæ¯ä¸ªèŠ‚ç‚¹æœ‰ Ci ç»´ç‰¹å¾

        Returns:
            expanded: æ‰©å±•åçš„ç‰¹å¾çŸ©é˜µï¼Œå½¢çŠ¶ (Ci, N, n)
                æ¯ä¸ªé€šé“ i å¯¹åº”ç‰¹å¾ç»´åº¦ iï¼ŒåŒ…å« NÃ—n çš„æ•°æ®

        å¯å¾®åˆ†æ€§ï¼š
            - unsqueeze å’Œ permuteï¼šå½¢çŠ¶æ“ä½œï¼Œå®Œå…¨å¯å¾®åˆ†
            - å¹¿æ’­ä¹˜æ³•ï¼šå®Œå…¨å¯å¾®åˆ†

        å®ç°æ–¹å¼ï¼š
            ä½¿ç”¨å¹¿æ’­æœºåˆ¶å°†ç‰¹å¾åº”ç”¨åˆ°æ•°æ®ä¸Šï¼š
            1. data: (N, n) -> (N, 1, n)
            2. features: (N, Ci) -> (N, Ci, 1)
            3. ç›¸ä¹˜å¾—åˆ°: (N, Ci, n)
            4. è½¬ç½®ä¸º: (Ci, N, n)

        ç¤ºä¾‹ï¼š
            data æ˜¯ 10 ä¸ªèŠ‚ç‚¹çš„åæ ‡ (10, 3)
            features æ˜¯ 10 ä¸ªèŠ‚ç‚¹çš„ç±»å‹ç‰¹å¾ (10, 5)
            è¾“å‡ºæ˜¯ (5, 10, 3)ï¼Œè¡¨ç¤º 5 ä¸ªç‰¹å¾é€šé“ï¼Œæ¯ä¸ªé€šé“æ˜¯ 10Ã—3 çš„åæ ‡çŸ©é˜µ
        """
        N, n = data.shape
        N_feat, Ci = features.shape

        # éªŒè¯è¾“å…¥ç»´åº¦åŒ¹é…
        assert N == N_feat, f"æ•°æ®å’Œç‰¹å¾çš„ç¬¬ä¸€ç»´åº¦å¿…é¡»åŒ¹é…: {N} != {N_feat}"

        # æ‰©å±•ç»´åº¦ä»¥è¿›è¡Œå¹¿æ’­
        data_expanded = data.unsqueeze(1)  # (N, 1, n)
        features_expanded = features.unsqueeze(2)  # (N, Ci, 1)

        # å¹¿æ’­ç›¸ä¹˜ï¼ˆå¯å¾®åˆ†ï¼‰
        result = data_expanded * features_expanded  # (N, Ci, n)

        # è½¬ç½®ä¸ºç›®æ ‡å½¢çŠ¶ (Ci, N, n)
        expanded = result.permute(1, 0, 2)

        return expanded

    def compute_relative_coordinates(
        self, local_coords: torch.Tensor, centers: torch.Tensor
    ) -> torch.Tensor:
        """
        åŠŸèƒ½ 2: ç›¸å¯¹åæ ‡è®¡ç®— (Decouple)ï¼ˆå¯å¾®åˆ†ï¼‰

        å°†ç»å¯¹åæ ‡è½¬æ¢ä¸ºç›¸å¯¹äºä¸­å¿ƒç‚¹çš„åæ ‡

        Args:
            local_coords: å±€éƒ¨åæ ‡ï¼Œå½¢çŠ¶ (N_centers, K, 3)
            centers: ä¸­å¿ƒç‚¹åæ ‡ï¼Œå½¢çŠ¶ (N_centers, 3)

        Returns:
            relative_coords: ç›¸å¯¹åæ ‡ï¼Œå½¢çŠ¶ (N_centers, K, 3)

        å¯å¾®åˆ†æ€§ï¼š
            - å‡æ³•æ“ä½œï¼šå®Œå…¨å¯å¾®åˆ†
            - å¹¿æ’­æœºåˆ¶ï¼šä¿æŒæ¢¯åº¦ä¼ æ’­
        """
        # å¹¿æ’­å¹¶ç›¸å‡ï¼ˆå¯å¾®åˆ†ï¼‰
        relative_coords = local_coords - centers.unsqueeze(1)

        return relative_coords

    def _apply_pca_batch_impl(
        self, relative_coords: torch.Tensor, epsilon: float
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        æ‰¹é‡ PCA å¯¹é½çš„æ ¸å¿ƒå®ç°ï¼ˆä¾› torch.compile ç¼–è¯‘ï¼‰
        
        è¿™ä¸ªå‡½æ•°ä¼šè¢« torch.compile ç¼–è¯‘æˆä¼˜åŒ–çš„èåˆæ ¸
        
        Args:
            relative_coords: (N_centers, K, 3)
            epsilon: æ•°å€¼ç¨³å®šåŒ–å‚æ•°
            
        Returns:
            aligned_coords: (N_centers, K, 3)
            eigenvalues: (N_centers, 3)
        """
        K = relative_coords.shape[1]
        device = relative_coords.device
        dtype = relative_coords.dtype
        
        # 1. æ‰¹é‡è®¡ç®—åæ–¹å·®çŸ©é˜µ
        cov_matrices = torch.bmm(
            relative_coords.transpose(1, 2),
            relative_coords
        ) / K
        
        # 2. æ•°å€¼ç¨³å®šåŒ–
        cov_matrices = cov_matrices + epsilon * torch.eye(
            3, device=device, dtype=dtype
        ).unsqueeze(0)
        
        # 3. æ‰¹é‡ç‰¹å¾å€¼åˆ†è§£
        eigenvalues, eigenvectors = torch.linalg.eigh(cov_matrices)
        
        # 4. æ‰¹é‡æŠ•å½±
        aligned_coords = torch.bmm(relative_coords, eigenvectors)
        
        return aligned_coords, eigenvalues

    def apply_rotation_invariance(
        self, relative_coords: torch.Tensor
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        åŠŸèƒ½ 3: å®ç°æ—‹è½¬ä¸å˜æ€§ (PCA/ä¸»æˆåˆ†åˆ†æ)ï¼ˆå¯å¾®åˆ† + å¹¶è¡ŒåŒ–ï¼‰

        è¿™æ˜¯æœ€éš¾ä¹Ÿæ˜¯æœ€å…³é”®çš„ä¸€æ­¥ï¼ç°åœ¨å·²ç»å‘é‡åŒ–ï¼Œæ”¯æŒæ‰¹é‡å¹¶è¡Œå¤„ç†ï¼

        Args:
            relative_coords: ç›¸å¯¹åæ ‡ï¼Œå½¢çŠ¶ (N_centers, K, 3)

        Returns:
            aligned_coords: å¯¹é½åçš„åæ ‡ï¼Œå½¢çŠ¶ (N_centers, K, 3)
            eigenvalues: ç‰¹å¾å€¼ï¼Œå½¢çŠ¶ (N_centers, 3)ï¼Œå¦‚æœä¸ä½¿ç”¨PCAåˆ™ä¸ºé›¶

        å¯å¾®åˆ†æ€§ï¼š
            - åæ–¹å·®è®¡ç®—ï¼šæ‰¹é‡çŸ©é˜µä¹˜æ³•ï¼Œå¯å¾®åˆ†
            - ç‰¹å¾å€¼åˆ†è§£ï¼štorch.linalg.eigh æ”¯æŒæ‰¹é‡æ“ä½œï¼Œå¯å¾®åˆ†
            - æŠ•å½±ï¼šæ‰¹é‡çŸ©é˜µä¹˜æ³•ï¼Œå¯å¾®åˆ†

        æ€§èƒ½ä¼˜åŒ–ï¼š
            - ä½¿ç”¨æ‰¹é‡çŸ©é˜µè¿ç®—ä»£æ›¿å¾ªç¯ï¼ˆå‘é‡åŒ–ï¼‰
            - åˆ©ç”¨ GPU å¹¶è¡Œå¤„ç†æ‰€æœ‰ä¸­å¿ƒç‚¹
            - æ€§èƒ½æå‡ 10-100 å€ï¼ˆå–å†³äº N_centersï¼‰
        """
        N_centers = relative_coords.shape[0]
        K = relative_coords.shape[1]
        device = relative_coords.device
        dtype = relative_coords.dtype

        # å¦‚æœä¸ä½¿ç”¨PCAï¼Œç›´æ¥è¿”å›ç›¸å¯¹åæ ‡ï¼ˆä¿æŒå¯å¾®åˆ†ï¼‰
        if not self.use_pca:
            aligned_coords = relative_coords.clone()
            eigenvalues = torch.zeros(N_centers, 3, device=device, dtype=dtype)
            return aligned_coords, eigenvalues

        # ========== å‘é‡åŒ–å®ç°ï¼šæ‰¹é‡ PCA å¯¹é½ ==========
        
        # è°ƒç”¨ç¼–è¯‘åçš„æ‰¹é‡ PCA å‡½æ•°
        epsilon = float(self.rotation_invariance.epsilon)
        aligned_coords, eigenvalues = self._apply_pca_batch(
            relative_coords, epsilon
        )

        return aligned_coords, eigenvalues

    def cartesian_to_spherical(self, coords: torch.Tensor) -> torch.Tensor:
        """
        åŠŸèƒ½ 4: ç¬›å¡å°”åæ ‡è½¬çƒæåæ ‡ï¼ˆå¯å¾®åˆ†ï¼‰

        å°† (x, y, z) è½¬æ¢ä¸º (r, Î¸, Ï†)

        Args:
            coords: ç¬›å¡å°”åæ ‡ï¼Œå½¢çŠ¶ (..., 3)

        Returns:
            spherical: çƒæåæ ‡ï¼Œå½¢çŠ¶ (..., 3)
                - r: å¾„å‘è·ç¦» [0, âˆ)
                - Î¸ (theta): æè§’/å¤©é¡¶è§’ [0, Ï€]
                - Ï† (phi): æ–¹ä½è§’ [0, 2Ï€)

        å¯å¾®åˆ†æ€§ï¼š
            - sqrt: å¯å¾®åˆ†ï¼ˆæ³¨æ„ r=0 æ—¶çš„æ•°å€¼ç¨³å®šæ€§ï¼‰
            - arccos: å¯å¾®åˆ†
            - atan2: å¯å¾®åˆ†

        æ•°å€¼ç¨³å®šæ€§ï¼š
            - é¿å…é™¤é›¶ï¼šå½“ r=0 æ—¶ä½¿ç”¨ epsilon
            - arccos çš„è¾“å…¥è£å‰ªåˆ° [-1, 1]

        å…¬å¼ï¼š
            r = sqrt(xÂ² + yÂ² + zÂ²)
            Î¸ = arccos(z / r)
            Ï† = atan2(y, x)
        """
        x = coords[..., 0]
        y = coords[..., 1]
        z = coords[..., 2]

        # è®¡ç®—å¾„å‘è·ç¦»ï¼ˆå¯å¾®åˆ†ï¼‰
        r = torch.sqrt(x**2 + y**2 + z**2 + 1e-10)  # åŠ  epsilon é¿å…æ¢¯åº¦çˆ†ç‚¸

        # é¿å…é™¤é›¶
        r_safe = torch.where(r < 1e-10, torch.ones_like(r) * 1e-10, r)

        # è®¡ç®—æè§’ Î¸ (theta): [0, Ï€]ï¼ˆå¯å¾®åˆ†ï¼‰
        theta = torch.acos(torch.clamp(z / r_safe, -1.0, 1.0))

        # è®¡ç®—æ–¹ä½è§’ Ï† (phi): [-Ï€, Ï€]ï¼ˆå¯å¾®åˆ†ï¼‰
        phi = torch.atan2(y, x)
        # è½¬æ¢åˆ° [0, 2Ï€)
        phi = torch.where(phi < 0, phi + 2 * torch.pi, phi)

        # ç»„åˆæˆçƒåæ ‡
        spherical = torch.stack([r, theta, phi], dim=-1)

        return spherical

    def forward(
        self,
        global_coords: torch.Tensor,
        neighbor_indices: torch.Tensor,
        global_features: Optional[torch.Tensor] = None,
    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, Optional[torch.Tensor]]:
        """
        å®Œæ•´çš„åæ ‡è½¬æ¢æµç¨‹ï¼ˆå¯å¾®åˆ†ï¼‰

        è¿™æ˜¯ä¸»æ¥å£å‡½æ•°ï¼Œä¸€æ¬¡æ€§å®Œæˆæ‰€æœ‰4ä¸ªæ­¥éª¤
        æ”¯æŒç«¯åˆ°ç«¯çš„æ¢¯åº¦åå‘ä¼ æ’­

        Args:
            global_coords: å…¨å±€ç»å¯¹åæ ‡ï¼Œå½¢çŠ¶ (N_total, 3)
            neighbor_indices: é‚»å±…ç´¢å¼•çŸ©é˜µï¼Œå½¢çŠ¶ (N_centers, K)
            global_features: å¯é€‰çš„å…¨å±€å±æ€§ç‰¹å¾ï¼Œå½¢çŠ¶ (N_total, Ci)
                å¦‚æœæä¾›ï¼Œå°†é€šè¿‡é‚»å±…ç´¢å¼•æ‰©å±•ä¸ºå±€éƒ¨ç‰¹å¾

        Returns:
            spherical_features: çƒæåæ ‡ç‰¹å¾ï¼Œå½¢çŠ¶ (N_centers, K, 3)
            centers: æ–°çš„ä¸­å¿ƒç‚¹åæ ‡ï¼Œå½¢çŠ¶ (N_centers, 3)
            eigenvalues: PCA ç‰¹å¾å€¼ï¼Œå½¢çŠ¶ (N_centers, 3)
            local_features: å±€éƒ¨å±æ€§ç‰¹å¾ï¼Œå½¢çŠ¶ (N_centers, K, Ci)
                å¦‚æœ global_features ä¸º Noneï¼Œåˆ™è¿”å› None

        æ¢¯åº¦æµåŠ¨ï¼š
            è¾“å…¥ global_coords (éœ€è¦æ¢¯åº¦)
              â†“ [ç´¢å¼•æ“ä½œ - å¯å¾®åˆ†]
            local_coords
              â†“ [å‡å€¼è®¡ç®— - å¯å¾®åˆ†]
            centers + relative_coords
              â†“ [PCA å¯¹é½ - å¯å¾®åˆ†]
            aligned_coords
              â†“ [çƒåæ ‡è½¬æ¢ - å¯å¾®åˆ†]
            spherical_features (æ¢¯åº¦å¯ä¼ å›è¾“å…¥)

            è¾“å…¥ global_features (éœ€è¦æ¢¯åº¦ï¼Œå¯é€‰)
              â†“ [ç´¢å¼•æ“ä½œ - å¯å¾®åˆ†]
            local_features (æ¢¯åº¦å¯ä¼ å›è¾“å…¥)
        """
        # æ­¥éª¤ 1: æå–å±€éƒ¨åæ ‡å¹¶è®¡ç®—ä¸­å¿ƒï¼ˆå¯å¾®åˆ†ï¼‰
        local_coords, centers = self.extract_local_coordinates(
            global_coords, neighbor_indices
        )

        # æ­¥éª¤ 1.5: æå–å±€éƒ¨å±æ€§ç‰¹å¾ï¼ˆå¯é€‰ï¼Œå¯å¾®åˆ†ï¼‰
        local_features = None
        if global_features is not None:
            local_features = self.extract_local_features(
                global_features, neighbor_indices
            )

        # æ­¥éª¤ 2: è®¡ç®—ç›¸å¯¹åæ ‡ï¼ˆå¹³ç§»ä¸å˜æ€§ï¼Œå¯å¾®åˆ†ï¼‰
        relative_coords = self.compute_relative_coordinates(local_coords, centers)

        # æ­¥éª¤ 3: PCA å¯¹é½ï¼ˆæ—‹è½¬ä¸å˜æ€§ï¼Œå¯å¾®åˆ†ï¼‰
        aligned_coords, eigenvalues = self.apply_rotation_invariance(relative_coords)

        # æ­¥éª¤ 4: è½¬æ¢ä¸ºçƒæåæ ‡ï¼ˆå¯å¾®åˆ†ï¼‰
        spherical_features = self.cartesian_to_spherical(aligned_coords)

        return spherical_features, centers, eigenvalues, local_features


# def test_differentiability():
#     """
#     æµ‹è¯•å®Œæ•´æ¨¡å—çš„å¯å¾®åˆ†æ€§
#     """
#     print("\n" + "=" * 70)
#     print("å®Œæ•´æ¨¡å—å¯å¾®åˆ†æ€§æµ‹è¯•")
#     print("=" * 70)

#     device = 'cuda' if torch.cuda.is_available() else 'cpu'
#     print(f"ä½¿ç”¨è®¾å¤‡: {device}")

#     torch.manual_seed(123)

#     # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®ï¼ˆéœ€è¦æ¢¯åº¦ï¼‰
#     N_total = 50
#     N_centers = 10
#     K = 8

#     global_coords = torch.randn(N_total, 3, device=device, requires_grad=True)
#     neighbor_indices = torch.randint(0, N_total, (N_centers, K), device=device)

#     print(f"\næ•°æ®è§„æ¨¡:")
#     print(f"  æ€»åŸå­æ•°: {N_total}")
#     print(f"  ä¸­å¿ƒç‚¹æ•°: {N_centers}")
#     print(f"  é‚»å±…æ•°: {K}")
#     print(f"  è¾“å…¥éœ€è¦æ¢¯åº¦: {global_coords.requires_grad}")

#     # åˆ›å»ºè½¬æ¢å™¨
#     transformer = CoordinateTransformerTorch(center_method='mean').to(device)

#     # å‰å‘ä¼ æ’­
#     print(f"\nå‰å‘ä¼ æ’­:")
#     spherical_features, centers, eigenvalues, local_features = transformer(
#         global_coords, neighbor_indices
#     )

#     print(f"  çƒåæ ‡ç‰¹å¾: {spherical_features.shape}, éœ€è¦æ¢¯åº¦: {spherical_features.requires_grad}")
#     print(f"  ä¸­å¿ƒç‚¹: {centers.shape}, éœ€è¦æ¢¯åº¦: {centers.requires_grad}")
#     print(f"  ç‰¹å¾å€¼: {eigenvalues.shape}, éœ€è¦æ¢¯åº¦: {eigenvalues.requires_grad}")
#     print(f"  å±€éƒ¨ç‰¹å¾: {local_features}")

#     # å®šä¹‰æŸå¤±å‡½æ•°
#     # è¿™é‡Œç”¨ä¸€ä¸ªç®€å•çš„æŸå¤±ï¼šçƒåæ ‡çš„å¾„å‘è·ç¦»çš„å¹³æ–¹å’Œ
#     r = spherical_features[..., 0]  # æå–å¾„å‘è·ç¦»
#     loss = (r ** 2).sum()

#     print(f"\nåå‘ä¼ æ’­:")
#     print(f"  æŸå¤±å€¼: {loss.item():.6f}")

#     # åå‘ä¼ æ’­
#     loss.backward()

#     print(f"  âœ“ åå‘ä¼ æ’­æˆåŠŸï¼")
#     print(f"  è¾“å…¥æ¢¯åº¦å½¢çŠ¶: {global_coords.grad.shape}")
#     print(f"  è¾“å…¥æ¢¯åº¦èŒƒæ•°: {global_coords.grad.norm().item():.6f}")
#     print(f"  è¾“å…¥æ¢¯åº¦éé›¶å…ƒç´ : {(global_coords.grad != 0).sum().item()} / {global_coords.grad.numel()}")

#     # æ£€æŸ¥æ¢¯åº¦æ˜¯å¦æœ‰æ•ˆ
#     assert global_coords.grad is not None, "æ¢¯åº¦ä¸ºç©ºï¼"
#     assert not torch.isnan(global_coords.grad).any(), "æ¢¯åº¦åŒ…å« NaNï¼"
#     assert not torch.isinf(global_coords.grad).any(), "æ¢¯åº¦åŒ…å« Infï¼"

#     print(f"\nâœ“ æ¢¯åº¦å¥åº·æ£€æŸ¥é€šè¿‡")

#     return True


# def test_feature_expansion():
#     """
#     æµ‹è¯•å±æ€§ç‰¹å¾æ‰©å±•åŠŸèƒ½
#     """
#     print("\n" + "=" * 70)
#     print("å±æ€§ç‰¹å¾æ‰©å±•æµ‹è¯•")
#     print("=" * 70)

#     device = 'cuda' if torch.cuda.is_available() else 'cpu'
#     print(f"ä½¿ç”¨è®¾å¤‡: {device}")

#     torch.manual_seed(789)

#     # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
#     N_total = 30      # æ€»åŸå­æ•°
#     N_centers = 8     # ä¸­å¿ƒç‚¹æ•°
#     K = 5             # æ¯ä¸ªä¸­å¿ƒçš„é‚»å±…æ•°
#     Ci = 10           # å±æ€§ç‰¹å¾ç»´åº¦ï¼ˆä¾‹å¦‚ï¼šåŸå­ç±»å‹çš„ one-hot ç¼–ç ï¼‰

#     global_coords = torch.randn(N_total, 3, device=device, requires_grad=True)
#     global_features = torch.randn(N_total, Ci, device=device, requires_grad=True)
#     neighbor_indices = torch.randint(0, N_total, (N_centers, K), device=device)

#     print(f"\næ•°æ®è§„æ¨¡:")
#     print(f"  æ€»åŸå­æ•° (N_total): {N_total}")
#     print(f"  ä¸­å¿ƒç‚¹æ•° (N_centers): {N_centers}")
#     print(f"  é‚»å±…æ•° (K): {K}")
#     print(f"  å±æ€§ç‰¹å¾ç»´åº¦ (Ci): {Ci}")

#     # åˆ›å»ºè½¬æ¢å™¨
#     transformer = CoordinateTransformerTorch(center_method='mean').to(device)

#     # å‰å‘ä¼ æ’­ï¼ˆå¸¦å±æ€§ç‰¹å¾ï¼‰
#     print(f"\nå‰å‘ä¼ æ’­ï¼ˆå¸¦å±æ€§ç‰¹å¾ï¼‰:")
#     spherical_features, centers, eigenvalues, local_features = transformer(
#         global_coords, neighbor_indices, global_features
#     )

#     print(f"  åæ ‡è¾“å…¥: {global_coords.shape} â†’ çƒåæ ‡è¾“å‡º: {spherical_features.shape}")
#     print(f"  å±æ€§è¾“å…¥: {global_features.shape} â†’ å±€éƒ¨å±æ€§è¾“å‡º: {local_features.shape}")
#     print(f"  ä¸­å¿ƒç‚¹: {centers.shape}")
#     print(f"  ç‰¹å¾å€¼: {eigenvalues.shape}")

#     # éªŒè¯å½¢çŠ¶
#     assert spherical_features.shape == (N_centers, K, 3), "çƒåæ ‡å½¢çŠ¶é”™è¯¯"
#     assert local_features.shape == (N_centers, K, Ci), "å±€éƒ¨å±æ€§å½¢çŠ¶é”™è¯¯"
#     assert centers.shape == (N_centers, 3), "ä¸­å¿ƒç‚¹å½¢çŠ¶é”™è¯¯"
#     assert eigenvalues.shape == (N_centers, 3), "ç‰¹å¾å€¼å½¢çŠ¶é”™è¯¯"

#     print(f"\nâœ“ è¾“å‡ºå½¢çŠ¶éªŒè¯é€šè¿‡")

#     # æµ‹è¯•å±æ€§ç‰¹å¾çš„æ¢¯åº¦ä¼ æ’­
#     print(f"\næµ‹è¯•å±æ€§ç‰¹å¾çš„æ¢¯åº¦ä¼ æ’­:")
#     loss = local_features.sum()
#     loss.backward()

#     print(f"  global_features æ¢¯åº¦å½¢çŠ¶: {global_features.grad.shape}")
#     print(f"  global_features æ¢¯åº¦èŒƒæ•°: {global_features.grad.norm().item():.6f}")
#     print(f"  global_features æ¢¯åº¦éé›¶å…ƒç´ : {(global_features.grad != 0).sum().item()} / {global_features.grad.numel()}")

#     # éªŒè¯æ¢¯åº¦çš„æ­£ç¡®æ€§ï¼šåªæœ‰è¢«é€‰ä¸­çš„åŸå­åº”è¯¥æœ‰æ¢¯åº¦
#     selected_indices = neighbor_indices.flatten().unique()
#     print(f"  è¢«é€‰ä¸­çš„åŸå­ç´¢å¼•æ•°: {len(selected_indices)}")

#     print(f"\nâœ“ å±æ€§ç‰¹å¾æ¢¯åº¦ä¼ æ’­æˆåŠŸ")

#     # æµ‹è¯•æ²¡æœ‰å±æ€§ç‰¹å¾çš„æƒ…å†µ
#     print(f"\nå‰å‘ä¼ æ’­ï¼ˆä¸å¸¦å±æ€§ç‰¹å¾ï¼‰:")
#     spherical_features2, centers2, eigenvalues2, local_features2 = transformer(
#         global_coords, neighbor_indices, None
#     )

#     print(f"  çƒåæ ‡è¾“å‡º: {spherical_features2.shape}")
#     print(f"  å±€éƒ¨å±æ€§è¾“å‡º: {local_features2}")

#     assert local_features2 is None, "ä¸æä¾›å±æ€§æ—¶åº”è¿”å› None"

#     print(f"\nâœ“ å¯é€‰å±æ€§ç‰¹å¾åŠŸèƒ½æ­£å¸¸")

#     return True


# def test_gradient_flow():
# """
# æµ‹è¯•æ¢¯åº¦æµåŠ¨çš„å®Œæ•´æ€§
# """
# print("\n" + "=" * 70)
# print("æ¢¯åº¦æµåŠ¨æµ‹è¯•")
# print("=" * 70)

# device = 'cpu'  # CPU æ›´å®¹æ˜“è°ƒè¯•
# torch.manual_seed(456)

# # åˆ›å»ºç®€å•çš„æµ‹è¯•æ¡ˆä¾‹
# N_total = 20
# N_centers = 5
# K = 4

# global_coords = torch.randn(N_total, 3, device=device, requires_grad=True)
# neighbor_indices = torch.randint(0, N_total, (N_centers, K), device=device)

# transformer = CoordinateTransformerTorch().to(device)

# # å‰å‘ä¼ æ’­
# spherical_features, centers, eigenvalues, local_features = transformer(
#     global_coords, neighbor_indices
# )

# # å¯¹æ¯ä¸ªè¾“å‡ºåˆ†åˆ«æµ‹è¯•æ¢¯åº¦
# print("\n1. çƒåæ ‡ç‰¹å¾çš„æ¢¯åº¦:")
# loss1 = spherical_features.sum()
# loss1.backward(retain_graph=True)
# grad1_norm = global_coords.grad.norm().item()
# print(f"   æ¢¯åº¦èŒƒæ•°: {grad1_norm:.6f}")
# global_coords.grad.zero_()

# print("\n2. ä¸­å¿ƒç‚¹çš„æ¢¯åº¦:")
# loss2 = centers.sum()
# loss2.backward(retain_graph=True)
# grad2_norm = global_coords.grad.norm().item()
# print(f"   æ¢¯åº¦èŒƒæ•°: {grad2_norm:.6f}")
# global_coords.grad.zero_()

# print("\n3. ç‰¹å¾å€¼çš„æ¢¯åº¦:")
# loss3 = eigenvalues.sum()
# loss3.backward()
# grad3_norm = global_coords.grad.norm().item()
# print(f"   æ¢¯åº¦èŒƒæ•°: {grad3_norm:.6f}")

# print(f"\nâœ“ æ‰€æœ‰è¾“å‡ºéƒ½èƒ½ä¼ æ’­æ¢¯åº¦åˆ°è¾“å…¥")

# return True


# # def test_expand_feature_matrix():
#     """
#     æµ‹è¯•ç‰¹å¾çŸ©é˜µæ‰©å±•åŠŸèƒ½
#     """
#     print("\n" + "=" * 70)
#     print("ç‰¹å¾çŸ©é˜µæ‰©å±•æµ‹è¯•")
#     print("=" * 70)

#     device = 'cuda' if torch.cuda.is_available() else 'cpu'
#     print(f"ä½¿ç”¨è®¾å¤‡: {device}")

#     torch.manual_seed(999)

#     # åˆ›å»ºæµ‹è¯•æ•°æ®
#     N = 10      # èŠ‚ç‚¹æ•°
#     n = 5       # æ¯ä¸ªèŠ‚ç‚¹çš„æ•°æ®ç»´åº¦ï¼ˆä¾‹å¦‚é‚»å±…æ•°ï¼‰
#     Ci = 8      # ç‰¹å¾ç»´åº¦

#     data = torch.randn(N, n, device=device, requires_grad=True)
#     features = torch.randn(N, Ci, device=device, requires_grad=True)

#     print(f"\næ•°æ®è§„æ¨¡:")
#     print(f"  æ•°æ®çŸ©é˜µ (data): {data.shape}")
#     print(f"  ç‰¹å¾çŸ©é˜µ (features): {features.shape}")

#     # åˆ›å»ºè½¬æ¢å™¨
#     transformer = CoordinateTransformerTorch().to(device)

#     # æµ‹è¯•ç‰¹å¾æ‰©å±•
#     print(f"\nå‰å‘ä¼ æ’­:")
#     expanded = transformer.expand_feature_matrix(data, features)

#     print(f"  è¾“å…¥: data {data.shape} + features {features.shape}")
#     print(f"  è¾“å‡º: expanded {expanded.shape}")
#     print(f"  éœ€è¦æ¢¯åº¦: {expanded.requires_grad}")

#     # éªŒè¯å½¢çŠ¶
#     expected_shape = (Ci, N, n)
#     assert expanded.shape == expected_shape, f"è¾“å‡ºå½¢çŠ¶é”™è¯¯: {expanded.shape} != {expected_shape}"

#     print(f"\nâœ“ è¾“å‡ºå½¢çŠ¶éªŒè¯é€šè¿‡: {expanded.shape}")

#     # æµ‹è¯•æ¢¯åº¦ä¼ æ’­
#     print(f"\næµ‹è¯•æ¢¯åº¦ä¼ æ’­:")
#     loss = expanded.sum()
#     loss.backward()

#     print(f"  data æ¢¯åº¦å½¢çŠ¶: {data.grad.shape}")
#     print(f"  data æ¢¯åº¦èŒƒæ•°: {data.grad.norm().item():.6f}")
#     print(f"  features æ¢¯åº¦å½¢çŠ¶: {features.grad.shape}")
#     print(f"  features æ¢¯åº¦èŒƒæ•°: {features.grad.norm().item():.6f}")

#     # éªŒè¯æ¢¯åº¦å¥åº·æ€§
#     assert data.grad is not None, "data æ¢¯åº¦ä¸ºç©ºï¼"
#     assert features.grad is not None, "features æ¢¯åº¦ä¸ºç©ºï¼"
#     assert not torch.isnan(data.grad).any(), "data æ¢¯åº¦åŒ…å« NaNï¼"
#     assert not torch.isnan(features.grad).any(), "features æ¢¯åº¦åŒ…å« NaNï¼"

#     print(f"\nâœ“ æ¢¯åº¦ä¼ æ’­æˆåŠŸï¼Œæ‰€æœ‰æ£€æŸ¥é€šè¿‡")

#     # æµ‹è¯•æ•°å€¼éªŒè¯
#     print(f"\næ•°å€¼éªŒè¯:")
#     # æ‰‹åŠ¨è®¡ç®—æœŸæœ›ç»“æœ
#     data_expanded_manual = data.unsqueeze(1)  # (N, 1, n)
#     features_expanded_manual = features.unsqueeze(2)  # (N, Ci, 1)
#     expected_manual = (data_expanded_manual * features_expanded_manual).permute(1, 0, 2)

#     diff = (expanded - expected_manual).abs().max().item()
#     print(f"  ä¸æ‰‹åŠ¨è®¡ç®—çš„æœ€å¤§å·®å¼‚: {diff:.2e}")

#     assert diff < 1e-6, f"æ•°å€¼éªŒè¯å¤±è´¥: {diff}"

#     print(f"\nâœ“ æ•°å€¼éªŒè¯é€šè¿‡")

#     return True


# if __name__ == "__main__":
# print("=" * 70)
# print("åæ ‡è½¬æ¢æ¨¡å— - PyTorch å¯å¾®åˆ†ç‰ˆæœ¬æµ‹è¯•")
# print("=" * 70)

# # # æµ‹è¯• 1: åŸºæœ¬å¯å¾®åˆ†æ€§
# # test_differentiability()

# # # æµ‹è¯• 2: æ¢¯åº¦æµåŠ¨
# # test_gradient_flow()


# print("\n" + "=" * 70)
# print("ğŸ‰ æ‰€æœ‰å¯å¾®åˆ†æ€§æµ‹è¯•é€šè¿‡ï¼")
# print("=" * 70)
# print("\nä½¿ç”¨å»ºè®®:")
# print("  1. å¯ä»¥ä½œä¸º nn.Module åµŒå…¥åˆ°ç¥ç»ç½‘ç»œä¸­")
# print("  2. æ”¯æŒ GPU åŠ é€Ÿï¼Œä¼ å…¥ device='cuda' çš„å¼ é‡")
# print("  3. æ”¯æŒæ‰¹é‡å¤„ç†å’Œç«¯åˆ°ç«¯è®­ç»ƒ")
# print("  4. æ³¨æ„: PCA åœ¨ç‰¹å¾å€¼é‡å¤æ—¶æ¢¯åº¦å¯èƒ½ä¸ç¨³å®š")
# print("=" * 70)
